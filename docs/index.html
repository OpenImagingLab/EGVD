<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EGVD: Event-Guided Video Diffusion Model</title>
</head>
<body>
    <header>
        <h1>EGVD: Event-Guided Video Diffusion Model</h1>
        <p>A Physically Realistic Large-Motion Frame Interpolation Approach</p>
    </header>
    <section>
        <h2>Overview</h2>
        <p>The Event-Guided Video Diffusion Model (EGVD) is designed to address challenges in large-motion frame interpolation by utilizing both event-based data and diffusion models for high-quality video synthesis.</p>
    </section>
    <section>
        <h2>Features</h2>
        <ul>
            <li>Uses event-based camera data for high temporal resolution.</li>
            <li>Integrates stable video diffusion models for improved frame interpolation.</li>
            <li>Works well under challenging conditions, such as large motion and low-light scenarios.</li>
        </ul>
    </section>
    <section>
        <h2>Getting Started</h2>
        <p>To get started with EGVD, you can clone this repository and follow the instructions in the README for installation and usage.</p>
    </section>
    <footer>
        <p>For more details, visit the <a href="https://github.com/OpenImagingLab/EGVD">EGVD GitHub Repository</a>.</p>
    </footer>
</body>
</html>
